name: FaaS Platform Tests

on:
  push:
    branches: [ main, develop, claude/* ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  # Unit tests - fast, no VM required
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        # vmtest is not needed for unit tests

    - name: Run unit tests
      run: |
        pytest tests/ -v -m "not vmtest" --tb=short

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: unit-test-results
        path: |
          .pytest_cache/
          *.log

  # Integration tests - use existing test.sh script
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y runc docker.io curl iproute2

        # Verify installations
        runc --version
        docker --version

    - name: Run integration test script
      run: |
        chmod +x test.sh
        sudo ./test.sh
      timeout-minutes: 10

    - name: Upload test logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: integration-test-logs
        path: |
          /tmp/faasd.log
          /tmp/deploy.log

  # Stress tests - long running
  stress-tests:
    name: Stress Tests
    runs-on: ubuntu-latest
    # Only run on main branch or manual trigger
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          runc \
          qemu-system-x86 \
          qemu-utils \
          docker.io

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        # Install vmtest from GitHub (not available on PyPI)
        pip install git+https://github.com/danobi/vmtest.git

    - name: Build test handler Docker image
      run: |
        docker build -f Dockerfile.test-handler -t test-handler .

    - name: Run stress tests
      run: |
        sudo -E env PATH=$PATH pytest tests/ -v -m "slow" --tb=short
      timeout-minutes: 45

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: stress-test-results
        path: |
          .pytest_cache/
          *.log

  # Code quality checks
  quality:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Check Python syntax
      run: |
        python -m py_compile faasd.py
        python -m py_compile faas
        python -m py_compile tests/*.py

    - name: Check for common issues
      run: |
        # Check for print statements that should be logging
        ! grep -r "print(" faasd.py || echo "Consider using logging instead of print"

        # Verify test files exist
        test -f tests/test_image_extraction.py
        test -f tests/test_container_lifecycle.py
        test -f tests/test_network_management.py
        test -f tests/test_socket_passing.py
        test -f tests/test_concurrency.py

        echo "✓ All core test files present"

  # Summary job
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, quality]
    if: always()

    steps:
    - name: Check test results
      run: |
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Code Quality: ${{ needs.quality.result }}"

        if [[ "${{ needs.unit-tests.result }}" == "failure" ]] || \
           [[ "${{ needs.integration-tests.result }}" == "failure" ]] || \
           [[ "${{ needs.quality.result }}" == "failure" ]]; then
          echo "❌ Some tests failed"
          exit 1
        else
          echo "✅ All tests passed"
        fi
